{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries.\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(\"Memory growth enabled\")\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the height and width to which each video frame will be resized in our dataset.\n",
    "IMAGE_HEIGHT , IMAGE_WIDTH = 128, 128\n",
    "\n",
    "# Specify the number of frames of a video that will be fed to the model as one sequence.\n",
    "SEQUENCE_LENGTH = 3\n",
    "\n",
    "DATASET_DIR = './/Screen_Capturing/Data/session_1/'\n",
    "DATA_DIR = './/Screen_Capturing/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict = {\"'mouse'\":'\"mouse\"',\"'click'\":'\"click\"',\"'keyboard'\":'\"keyboard\"',\"['\":'[\"',\"', '\":'\", \"', \"']\":'\"]'}\n",
    "\n",
    "def clean_input(input):\n",
    "    for key, value in replace_dict.items():\n",
    "        input = input.replace(key, value)\n",
    "    return input\n",
    "\n",
    "def parse_dataset(dataset_dir, lower_dir):\n",
    "    with open(os.path.join(dataset_dir,'data.txt'), 'r', encoding=\"utf-8\") as file:\n",
    "        files_data = file.read().split(\"\\n\")\n",
    "        \n",
    "    lower_dir = os.path.join('.//', lower_dir)\n",
    "    records = []\n",
    "    for file_data in files_data:\n",
    "        if file_data == \"\":\n",
    "            continue\n",
    "        file_name, inputs = file_data.split(\"\\t\")\n",
    "        inputs = clean_input(inputs)\n",
    "        inputs = json.loads(inputs)\n",
    "        file_name = os.path.join(dataset_dir, file_name + '.jpeg')\n",
    "        data = inputs[\"mouse\"][0], inputs[\"mouse\"][1], inputs[\"click\"][0], inputs[\"keyboard\"], file_name\n",
    "        records.append(data)\n",
    "\n",
    "    return records\n",
    "\n",
    "def load_dataset():\n",
    "    df = pd.DataFrame()\n",
    "    dfs = []\n",
    "    os_list = os.listdir(DATA_DIR)\n",
    "    for i in os_list:\n",
    "        if i.startswith('session'):\n",
    "            dataset_dir = os.path.join(DATA_DIR, i)\n",
    "            dataset = parse_dataset(dataset_dir, i)\n",
    "            labeled_df = pd_dataset(dataset)\n",
    "            dfs.append(labeled_df)\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    return df\n",
    "\n",
    "def pd_dataset(dataset):\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df.columns = ['x', 'y', 'click', 'keyboard', 'file']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset()\n",
    "print(df)\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignored_index = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_keys_list = ['w','s','a','d','shift','e','q','1','2','r','ctrl','space']\n",
    "valid_click_list = [\"Button.left\",\"Button.right\"]\n",
    "\n",
    "\n",
    "actions = ['click','for_back_move','left_right_move','shift','e','q','selection','r']\n",
    "\n",
    "def clean_data(df):\n",
    "    \n",
    "    records = []\n",
    "\n",
    "    for index, key in df.iterrows():\n",
    "        data = [0]*12 \n",
    "        keyboard_keys = str(key['keyboard'])\n",
    "        keyboard_keys = keyboard_keys.replace(\"'\", '\"')\n",
    "        keyboard_keys = json.loads(keyboard_keys)\n",
    "\n",
    "        for i, action in enumerate(keyboard_keys):\n",
    "            keyboard_keys[i] = str(action)\n",
    "        \n",
    "\n",
    "        data[0] = int(key['x'])\n",
    "        data[1] = int(key['y'])\n",
    "\n",
    "        data[2] = 1 if key['click'] == 'Button.left' else 2 if key['click'] == 'Button.right' else 0\n",
    "\n",
    "        data[3] = 1 if 'w' in keyboard_keys else 2 if 's' in keyboard_keys else 0\n",
    "\n",
    "        data[4] = 1 if 'a' in keyboard_keys else 2 if 'd' in keyboard_keys else 0\n",
    "\n",
    "\n",
    "        if 'Key.shift' in keyboard_keys:\n",
    "            data[5] = 1\n",
    "\n",
    "        if 'e' in keyboard_keys:\n",
    "            data[6] = 1\n",
    "\n",
    "        if 'q' in keyboard_keys:\n",
    "            data[7] = 1\n",
    "\n",
    "        data[8] = 1 if '1' in keyboard_keys else 2 if '2' in keyboard_keys else 0\n",
    "\n",
    "        if 'r' in keyboard_keys:\n",
    "            data[9] = 1\n",
    "\n",
    "        if 'ctrl' in keyboard_keys:\n",
    "            data[10] = 1\n",
    "\n",
    "        if '<32>' in keyboard_keys:\n",
    "            data[11] = 1\n",
    "\n",
    "        data.append(key['file'])\n",
    "\n",
    "        records.append(data)\n",
    "    return records\n",
    "\n",
    "def pd_labels(dataset):\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df.columns = ['x','y','click','for_back_move','left_right_move','shift','e','q','selection','r','ctrl','space','file']\n",
    "\n",
    "    return df\n",
    "\n",
    "clean_dataset = clean_data(df)\n",
    "clean_df = pd_labels(clean_dataset)\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(clean_df.head(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['click'].values[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "print(clean_df['click'].values[0:10].shape)\n",
    "\n",
    "toq = to_categorical(clean_df['click'].values)\n",
    "\n",
    "toq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_x = df['x'].max()\n",
    "max_y = df['y'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class DataGenerator():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def generate_split_indexes(self):\n",
    "        p = np.random.permutation(len(df))\n",
    "        print(p)\n",
    "        train_up_to = int(len(df))\n",
    "        train_idx = p[:train_up_to]\n",
    "        test_idx = p[train_up_to:]\n",
    "        train_up_to = int(train_up_to)\n",
    "        train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:]\n",
    "\n",
    "\n",
    "        self.max_x = df['x'].max()\n",
    "        self.max_y = df['y'].max()\n",
    "        return train_idx, valid_idx, test_idx\n",
    "\n",
    "    def preprocess_image(self, img_path):\n",
    "        \"\"\"\n",
    "        Used to perform some minor preprocessing on the image before inputting into the network.\n",
    "        \"\"\"\n",
    "        im = Image.open(img_path).convert('RGB')\n",
    "        im = cv2.resize(im, (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation=cv2.INTER_AREA)\n",
    "        im = np.array(im) / 255.0\n",
    "        \n",
    "        return im\n",
    "\n",
    "    def frame_extraction(self, index, df):\n",
    "\n",
    "        frames_list = []\n",
    "        for k in range(SEQUENCE_LENGTH):\n",
    "            frame = np.array(Image.open(os.path.join(str(self.df['file'].values[index-k])))) # removed DATASET_DIR, '.jpeg'\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = cv2.resize(frame, (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
    "            frame = frame / 255.0\n",
    "            frames_list.append(frame)\n",
    "\n",
    "        return frames_list\n",
    "\n",
    "    def labels_extraction(self, index, name, df):\n",
    "        label_list = []\n",
    "        for k in range(SEQUENCE_LENGTH):\n",
    "            label = self.df[name].values[index-k]\n",
    "            label_list.append(label)\n",
    "\n",
    "        return label_list\n",
    "\n",
    "    def generate(self, image_idx, is_training, batch_size=32):\n",
    "        \"\"\"\n",
    "        Generates batches of samples\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            frames_list = []\n",
    "            labels = []\n",
    "            x_labels_list = []\n",
    "            y_labels_list = []\n",
    "            click_labels_list = []\n",
    "            for_back_move_labels_list = []\n",
    "            left_right_move_labels_list = []\n",
    "            shift_labels_list = []\n",
    "            e_labels_list = []\n",
    "            q_labels_list = []\n",
    "            selection_labels_list = []\n",
    "            r_labels_list = []\n",
    "            ctrl_labels_list = []\n",
    "            space_labels_list = []\n",
    "\n",
    "            for idx in image_idx:\n",
    "                if idx + SEQUENCE_LENGTH >= len(self.df):\n",
    "                    continue\n",
    "                if idx - SEQUENCE_LENGTH < 0:\n",
    "                    continue\n",
    "\n",
    "                if len(frames_list) != batch_size:\n",
    "                    frames = self.frame_extraction(idx, self.df)\n",
    "                    x_labels = self.labels_extraction(idx, 'x', self.df)\n",
    "                    y_labels = self.labels_extraction(idx, 'y', self.df)\n",
    "                    click_labels = self.labels_extraction(idx, 'click', self.df)\n",
    "                    for_back_move_labels = self.labels_extraction(idx, 'for_back_move', self.df)\n",
    "                    left_right_move_labels = self.labels_extraction(idx, 'left_right_move', self.df)\n",
    "                    shift_labels = self.labels_extraction(idx, 'shift', self.df)\n",
    "                    e_labels = self.labels_extraction(idx, 'e', self.df)\n",
    "                    q_labels = self.labels_extraction(idx, 'q', self.df)\n",
    "                    selection_labels = self.labels_extraction(idx, 'selection', self.df)\n",
    "                    r_labels = self.labels_extraction(idx, 'r', self.df)\n",
    "                    ctrl_labels = self.labels_extraction(idx, 'ctrl', self.df)\n",
    "                    space_labels = self.labels_extraction(idx, 'space', self.df)\n",
    "\n",
    "                    x_labels = np.array(x_labels)/self.max_x\n",
    "                    y_labels = np.array(y_labels)/self.max_y\n",
    "\n",
    "                    click_labels = np.array(click_labels)\n",
    "                    for_back_move_labels = np.array(for_back_move_labels)\n",
    "                    left_right_move_labels = np.array(left_right_move_labels)\n",
    "                    shift_labels = np.array(shift_labels)\n",
    "                    e_labels = np.array(e_labels)\n",
    "                    q_labels = np.array(q_labels)\n",
    "                    selection_labels = np.array(selection_labels)\n",
    "                    r_labels = np.array(r_labels)\n",
    "                    ctrl_labels = np.array(ctrl_labels)\n",
    "                    space_labels = np.array(space_labels)\n",
    "                    \n",
    "                    frames_list.append(frames)\n",
    "\n",
    "                    x_labels_list.append(x_labels)\n",
    "                    y_labels_list.append(y_labels)\n",
    "                    click_labels_list.append(click_labels)\n",
    "                    for_back_move_labels_list.append(for_back_move_labels)\n",
    "                    left_right_move_labels_list.append(left_right_move_labels)\n",
    "                    shift_labels_list.append(shift_labels)\n",
    "                    e_labels_list.append(e_labels)\n",
    "                    q_labels_list.append(q_labels)\n",
    "                    selection_labels_list.append(selection_labels)\n",
    "                    r_labels_list.append(r_labels)\n",
    "                    ctrl_labels_list.append(ctrl_labels)\n",
    "                    space_labels_list.append(space_labels)\n",
    "\n",
    "\n",
    "\n",
    "                if len(frames_list) == batch_size:\n",
    "                    yield np.array(frames_list), [np.array(x_labels_list), np.array(y_labels_list), np.array(click_labels_list), np.array(for_back_move_labels_list), np.array(left_right_move_labels_list), np.array(shift_labels_list), np.array(e_labels_list), np.array(q_labels_list), np.array(selection_labels_list), np.array(r_labels_list), np.array(ctrl_labels_list), np.array(space_labels_list)]\n",
    "                    \"\"\"\n",
    "                    frames_list = []\n",
    "                    x_labels_list = []\n",
    "                    y_labels_list = []\n",
    "                    click_labels_list = []\n",
    "                    for_back_move_labels_list = []\n",
    "                    left_right_move_labels_list = []\n",
    "                    shift_labels_list = []\n",
    "                    e_labels_list = []\n",
    "                    q_labels_list = []\n",
    "                    selection_labels_list = []\n",
    "                    r_labels_list = []\n",
    "                    ctrl_labels_list = []\n",
    "                    space_labels_list = []\n",
    "                    \"\"\"\n",
    "            if not is_training:\n",
    "                break\n",
    "data_generator = DataGenerator(clean_df)\n",
    "train_idx, valid_idx, test_idx = data_generator.generate_split_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, ConvLSTM2D, MaxPooling2D, MaxPooling3D,BatchNormalization, Input, LSTM, TimeDistributed, Bidirectional,Conv3D, Rescaling\n",
    "from keras.models import Sequential, Model\n",
    "class create_ConvLSTM_model():\n",
    "\n",
    "    def dense_block(self, inputs, units, activation=\"relu\"):\n",
    "        x = Dense(units)(inputs)\n",
    "        x = Activation(activation)(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "    def build_x_position_branch(self, inputs, num_outputs=1):\n",
    "        x = self.dense_block(inputs, 1048)\n",
    "        # x = self.dense_block(x, 128)\n",
    "        x = self.dense_block(x, 16)\n",
    "        x = Dense(num_outputs)(x)\n",
    "        x = Activation(\"linear\", name='x')(x)\n",
    "        return x\n",
    "\n",
    "    def build_y_position_branch(self, inputs, num_outputs=1):\n",
    "        x = self.dense_block(inputs, 1048)\n",
    "        # x = self.dense_block(x, 128)\n",
    "        x = self.dense_block(x, 16)\n",
    "        x = Dense(num_outputs)(x)\n",
    "        x = Activation(\"linear\", name='y')(x)\n",
    "        return x\n",
    "\n",
    "    def build_softmax_branch(self, inputs, name, num_outputs=3):\n",
    "        x = self.dense_block(inputs, 1048)\n",
    "        # x = self.dense_block(x, 128)\n",
    "        x = self.dense_block(x, 16)\n",
    "        x = Dense(num_outputs)(x)\n",
    "        x = Activation(\"softmax\", name=name)(x)\n",
    "        return x\n",
    "\n",
    "    def build_action_branch(self, inputs, name, num_outputs=1):\n",
    "        x = self.dense_block(inputs, 1048)\n",
    "        # x = self.dense_block(x, 128)\n",
    "        x = self.dense_block(x, 16)\n",
    "        x = Dense(num_outputs)(x)\n",
    "        x = Activation(\"sigmoid\", name=name)(x)\n",
    "        return x\n",
    "\n",
    "    def build_model(self):\n",
    "        '''\n",
    "        This function will construct the required LRCN model.\n",
    "        Returns:\n",
    "            model: It is the required constructed LRCN model.\n",
    "        '''\n",
    "\n",
    "        # We will use a Sequential model for model construction.\n",
    "        inputs = Input(shape=(SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
    "\n",
    "        #x = Rescaling(1./255)(inputs)\n",
    "\n",
    "        x = ConvLSTM2D(filters = 16, kernel_size = (5, 5), activation = 'tanh',data_format = \"channels_last\",\n",
    "                         recurrent_dropout=0.2, return_sequences=True)(inputs)\n",
    "        x = MaxPooling3D(pool_size=(1, 3, 3), padding='same', data_format='channels_last')(x)\n",
    "        x = TimeDistributed(Dropout(0.5))(x)\n",
    "\n",
    "        x = ConvLSTM2D(filters = 32, kernel_size = (5, 5), activation = 'tanh', data_format = \"channels_last\",\n",
    "                         recurrent_dropout=0.2, return_sequences=True)(x)\n",
    "        x = MaxPooling3D(pool_size=(1, 3, 3), padding='same', data_format='channels_last')(x)\n",
    "        x = TimeDistributed(Dropout(0.5))(x)\n",
    "        \n",
    "        x = ConvLSTM2D(filters = 64, kernel_size = (5, 5), activation = 'tanh', data_format = \"channels_last\",\n",
    "                            recurrent_dropout=0.2, return_sequences=True)(x)\n",
    "        x = MaxPooling3D(pool_size=(1, 3, 3), padding='same', data_format='channels_last')(x)\n",
    "        x = TimeDistributed(Dropout(0.2))(x)\n",
    "        \n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = self.dense_block(x, 1024)\n",
    "        x = self.dense_block(x, 2048)\n",
    "\n",
    "        x_position = self.build_x_position_branch(x)\n",
    "        y_position = self.build_y_position_branch(x)\n",
    "        click = self.build_softmax_branch(x, \"click\")\n",
    "        for_back_move = self.build_softmax_branch(x, \"for_back_move\")\n",
    "        left_right_move = self.build_softmax_branch(x, \"left_right_move\")\n",
    "        shift = self.build_action_branch(x, \"shift\")\n",
    "        e = self.build_action_branch(x, \"e\")\n",
    "        q = self.build_action_branch(x, \"q\")\n",
    "        selection = self.build_softmax_branch(x, \"selection\")\n",
    "        r = self.build_action_branch(x, \"r\")\n",
    "        ctrl = self.build_action_branch(x, \"ctrl\")\n",
    "        space = self.build_action_branch(x, \"space\")\n",
    "\n",
    "        model = Model(inputs=inputs, outputs=[x_position, y_position, click, for_back_move, left_right_move, shift, e, q, selection, r, ctrl, space])\n",
    "\n",
    "        return model\n",
    "\n",
    "model = create_ConvLSTM_model().build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "init_lr = 1e-4\n",
    "epochs = 25\n",
    "opt = Adam(learning_rate=init_lr, decay=init_lr / epochs)\n",
    "# , decay=init_lr / epochs\n",
    "binary_actions = ['shift', 'e', 'q', 'r', 'ctrl', 'space']\n",
    "\n",
    "categorical_actions = ['click', 'for_back_move', 'left_right_move','selection']\n",
    "\n",
    "loss = {'x': 'mse', 'y': 'mse'}\n",
    "for index, key in enumerate(binary_actions):\n",
    "    loss[key] = 'binary_crossentropy'\n",
    "for index, key in enumerate(categorical_actions):\n",
    "    loss[key] = 'categorical_crossentropy'\n",
    "\n",
    "loss_weights = {'x': 1.0, 'y': 1.0}\n",
    "for index, key in enumerate(binary_actions):\n",
    "    loss_weights[key] = 0.5\n",
    "for index, key in enumerate(categorical_actions):\n",
    "    loss_weights[key] = 2.0\n",
    "\n",
    "metrics = {'x': 'mae', 'y': 'mae'}\n",
    "for index, key in enumerate(binary_actions):\n",
    "    metrics[key] = 'accuracy'\n",
    "for index, key in enumerate(categorical_actions):\n",
    "    metrics[key] = 'categorical_accuracy'\n",
    "\n",
    "model.compile(optimizer=opt, \n",
    "              loss=loss,\n",
    "              loss_weights=loss_weights,\n",
    "              metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "batch_size = 32\n",
    "train_gen = data_generator.generate(train_idx, is_training=True, batch_size=batch_size)\n",
    "valid_gen = data_generator.generate(valid_idx, is_training=True, batch_size=batch_size)\n",
    "callbacks = {\n",
    "    'checkpoint': ModelCheckpoint('model-{epoch:03d}.h5', monitor='loss', verbose=0, save_best_only=True, mode='auto'),\n",
    "}\n",
    "\n",
    "step_size_train = len(train_idx)//batch_size\n",
    "step_size_train = 200\n",
    "step_size_valid = len(valid_idx)//batch_size\n",
    "step_size_valid = 50\n",
    "\n",
    "# model.load_weights('model-007.h5')\n",
    "\n",
    "history = model.fit(train_gen,\n",
    "                    steps_per_epoch=step_size_train,\n",
    "                    epochs=epochs, \n",
    "                    callbacks=[callbacks['checkpoint']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model-005.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(img):\n",
    "    img = np.array(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
    "    return img\n",
    "\n",
    "def pred_frame(img_past, img_present, img_future):\n",
    "    img_past_list, img_present_list, img_future_list = [], [], []\n",
    "\n",
    "\n",
    "    img_past = process_img(img_past)\n",
    "    img_present = process_img(img_present)\n",
    "    img_future = process_img(img_future)\n",
    "\n",
    "    images = [np.array(img_past), np.array(img_present), np.array(img_future)]\n",
    "\n",
    "\n",
    "    x_pred, y_pred, click_pred, for_back_move_pred, left_right_move_pred, shift_pred, e_pred, q_pred, selection_pred, r_pred, ctrl_pred, space_pred = model.predict(np.expand_dims(images, axis = 0), verbose=0)\n",
    "    \n",
    "    click_pred, for_back_move_pred, left_right_move_pred, shift_pred, e_pred, q_pred, selection_pred, r_pred, ctrl_pred, space_pred = click_pred.argmax(axis=-1), for_back_move_pred.argmax(axis=-1), left_right_move_pred.argmax(axis=-1), shift_pred.argmax(axis=-1), e_pred.argmax(axis=-1), q_pred.argmax(axis=-1), selection_pred.argmax(axis=-1), r_pred.argmax(axis=-1), ctrl_pred.argmax(axis=-1), space_pred.argmax(axis=-1)\n",
    "\n",
    "    x_pred, y_pred = x_pred * max_x, y_pred * max_y\n",
    "\n",
    "    print(click_pred, for_back_move_pred, left_right_move_pred, shift_pred)\n",
    "\n",
    "    return x_pred[0], y_pred[0], click_pred[0], for_back_move_pred[0], left_right_move_pred[0], shift_pred[0], e_pred[0], q_pred[0], selection_pred[0], r_pred[0], ctrl_pred[0], space_pred[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import win32gui\n",
    "from PIL import ImageGrab\n",
    "from time import time\n",
    "import cv2 as cv\n",
    "from pynput.mouse import Listener as MouseListener\n",
    "from pynput.keyboard import Listener as KeyboardListener\n",
    "from pynput.keyboard import Key\n",
    "\n",
    "loop_time = time()\n",
    "first_frame = True\n",
    "ind = 0\n",
    "\n",
    "\n",
    "screenshot = None\n",
    "past_screenshot = None\n",
    "past_1_screenshot = None\n",
    "past_2_screenshot = None\n",
    "past_3_screenshot = None\n",
    "\n",
    "color = (255, 0, 0)\n",
    "\n",
    "while(True):\n",
    "    ind += 1\n",
    "    # print(ind)\n",
    "    hwnd = win32gui.FindWindow(None, 'Overwatch')\n",
    "    rect = win32gui.GetWindowRect(hwnd)\n",
    "    screenshot = ImageGrab.grab(bbox=(rect[0], rect[1], rect[2], rect[3]))\n",
    "\n",
    "\n",
    "    if ind <= 2:\n",
    "        past_screenshot = screenshot\n",
    "        continue\n",
    "\n",
    "    past_1_screenshot = past_screenshot\n",
    "    past_screenshot = screenshot\n",
    "\n",
    "\n",
    "    x_pred, y_pred, click_pred, for_back_move_pred, left_right_move_pred, shift_pred, e_pred, q_pred, selection_pred, r_pred, ctrl_pred, space_pred = pred_frame(screenshot, past_screenshot, past_1_screenshot)\n",
    "\n",
    "    screenshot = np.array(screenshot)\n",
    "\n",
    "    if click_pred == 1:\n",
    "        color = (0, 255, 0)\n",
    "    elif click_pred == 2:\n",
    "        color = (0, 0, 255)\n",
    "    else:\n",
    "        color = (255, 0, 0)\n",
    "    screenshot = cv2.circle(screenshot, (int(x_pred), int(y_pred)), 5, color, -1)\n",
    "\n",
    "    screenshot = cv.cvtColor(screenshot, cv.COLOR_RGB2BGR)\n",
    "\n",
    "    cv.imshow('Computer Vision', screenshot)\n",
    "\n",
    "    print('FPS {}'.format(1 / (time() - loop_time)))\n",
    "    loop_time = time()\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6c45bb627ecccf9ae3ce9e05118981924de35e00a1cec08fbfa0bd71913be76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
