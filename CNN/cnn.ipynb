{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "dataset_folder_name = './/Screen_Capturing/Data'\n",
    "TRAIN_TEST_SPLIT = 0.8\n",
    "IM_WIDTH = 198\n",
    "IM_HEIGHT = 198\n",
    "IMAGE_SAMPLE_SIZE = 7800"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict = {\"'mouse'\":'\"mouse\"',\"'click'\":'\"click\"',\"'keyboard'\":'\"keyboard\"',\"['\":'[\"',\"', '\":'\", \"', \"']\":'\"]'}\n",
    "\n",
    "def clean_input(input):\n",
    "    for key, value in replace_dict.items():\n",
    "        input = input.replace(key, value)\n",
    "    return input\n",
    "\n",
    "def parse_dataset():\n",
    "    with open(os.path.join(dataset_folder_name,'data.txt'), 'r', encoding=\"utf-8\") as file:\n",
    "        files_data = file.read().split(\"\\n\")\n",
    "        \n",
    "    records = []\n",
    "    for file_data in files_data[: min(IMAGE_SAMPLE_SIZE, len(files_data)-1)]:\n",
    "        file_name, inputs = file_data.split(\"\\t\")\n",
    "        inputs = clean_input(inputs)\n",
    "        inputs = json.loads(inputs)\n",
    "        file_name = file_name + \"\"\n",
    "        data = inputs[\"mouse\"][0], inputs[\"mouse\"][1], inputs[\"click\"][0], inputs[\"keyboard\"], file_name\n",
    "        records.append(data)\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_dataset(dataset):\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df.columns = ['x', 'y', 'click', 'keyboard', 'file']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = parse_dataset()\n",
    "df = pd_dataset(dataset)\n",
    "df.head(100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binwidth = 10\n",
    "\n",
    "x_values = df['x'].values.tolist()\n",
    "y_values = df['y'].values.tolist()\n",
    "\n",
    "plt.hist(df['x'],bins=range(min(df['x']), 1920 + binwidth, binwidth))\n",
    "plt.hist(df['y'],bins=range(min(df['y']), 1080 + binwidth, binwidth))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['click'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myplot(s,bins=1000):\n",
    "    heatmap, xedges, yedges = np.histogram2d(x_values, y_values, bins=bins)\n",
    "    heatmap = gaussian_filter(heatmap, sigma=s)\n",
    "\n",
    "    extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "    return heatmap.T, extent\n",
    "\n",
    "\n",
    "s = 64\n",
    "img, extent = myplot(s)\n",
    "plt.imshow(img, extent=extent, origin='lower', cmap=cm.jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['keyboard'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, key in df.iterrows():\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_keys_list = ['w','s','a','d','shift','e','q','1','2','r']\n",
    "valid_click_list = [\"Button.left\",\"Button.right\"]\n",
    "\n",
    "data = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "def clean_data(df):\n",
    "    \n",
    "    records = []\n",
    "\n",
    "    for index, key in df.iterrows():\n",
    "        data = [0] * 10\n",
    "        keyboard_keys = str(key['keyboard'])\n",
    "        keyboard_keys = keyboard_keys.replace(\"'\", '\"')\n",
    "        keyboard_keys = json.loads(keyboard_keys)\n",
    "\n",
    "        data.insert(0, int(key['x']))\n",
    "        data.insert(1, int(key['y']))\n",
    "\n",
    "        for i, k in enumerate(valid_keys_list):\n",
    "            if k in keyboard_keys:\n",
    "                data[i+2] = 1\n",
    "\n",
    "        if valid_click_list[0] in key['click']:\n",
    "            data.insert(2, 1)\n",
    "        else:\n",
    "            data.insert(2, 0)\n",
    "\n",
    "        if valid_click_list[1] in key['click']:\n",
    "            data.insert(3, 1)\n",
    "        else:\n",
    "            data.insert(3, 0)\n",
    "\n",
    "        data.append(key['file'])\n",
    "\n",
    "        records.append(data)\n",
    "    return records\n",
    "\n",
    "def pd_labels(dataset):\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df.columns = ['x','y','left_click','right_click','w','s','a','d','shift','e','q','1','2','r','file']\n",
    "\n",
    "    return df\n",
    "\n",
    "dataset = clean_data(df)\n",
    "df = pd_labels(dataset)\n",
    "df.head(100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Editing Data to # of occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_key(key, dict):\n",
    "    key = str(key)\n",
    "    key = key.replace(\"'\", '\"')\n",
    "    key = json.loads(key)\n",
    "    if not key:\n",
    "        if '' not in dict:\n",
    "            dict[''] = 1\n",
    "        else:\n",
    "            dict[''] += 1\n",
    "    for i in range(len(key)):\n",
    "        if key[i] not in dict:\n",
    "            dict[key[i]] = 1\n",
    "        else:\n",
    "            dict[key[i]] += 1\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyboard_data = {}\n",
    "\n",
    "for i in df['keyboard']:\n",
    "    keyboard_data = add_key(i, keyboard_data)\n",
    "\n",
    "keyboard_data = {k: v for k, v in sorted(keyboard_data.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "keyboard_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display # of occurances of keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(keyboard_data.keys())\n",
    "values = list(keyboard_data.values())\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.bar(keys[:15], values[:15], log=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truncate Data to the top 10 most occured keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "dataset_dict = {}\n",
    "dataset = {}\n",
    "for i in range(len(keyboard_data)):\n",
    "    dataset[i] = keys[i]\n",
    "\n",
    "dataset_dict[\"keyboard\"] = dict(itertools.islice(dataset.items(), 0, 10))\n",
    "\n",
    "dataset_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clicks dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_click(click, dict):\n",
    "    click = str(click)\n",
    "    click = click.replace(\"'\", '\"')\n",
    "    if not click:\n",
    "        if '' not in dict:\n",
    "            dict[''] = 1\n",
    "        else:\n",
    "            dict[''] += 1\n",
    "    elif click not in dict:\n",
    "        dict[click] = 1\n",
    "    else:\n",
    "        dict[click] += 1\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_data = {}\n",
    "\n",
    "for i in df['click']:\n",
    "    click_data = add_click(i, click_data)\n",
    "\n",
    "click_data = {k: v for k, v in sorted(click_data.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "dataset_dict[\"click\"] = click_data\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for types in dataset_dict:\n",
    "    dataset_dict[types] = dict((g, i) for i, g in dataset_dict[types].items())\n",
    "\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_x = df['x'].max()\n",
    "max_y = df['y'].max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class DataGenerator():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def generate_split_indexes(self):\n",
    "        p = np.random.permutation(len(df))\n",
    "        print(p)\n",
    "        train_up_to = int(len(df) * TRAIN_TEST_SPLIT)\n",
    "        train_idx = p[:train_up_to]\n",
    "        test_idx = p[train_up_to:]\n",
    "        train_up_to = int(train_up_to * TRAIN_TEST_SPLIT)\n",
    "        train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:]\n",
    "\n",
    "\n",
    "        self.max_x = df['x'].max()\n",
    "        self.max_y = df['y'].max()\n",
    "        return train_idx, valid_idx, test_idx\n",
    "\n",
    "    def preprocess_image(self, img_path):\n",
    "        \"\"\"\n",
    "        Used to perform some minor preprocessing on the image before inputting into the network.\n",
    "        \"\"\"\n",
    "        im = Image.open(img_path).convert('RGB')\n",
    "        im = im.resize((IM_WIDTH, IM_HEIGHT))\n",
    "        im = np.array(im) / 255.0\n",
    "        \n",
    "        return im\n",
    "        \n",
    "    def generate_images(self, image_idx, is_training, batch_size=16):\n",
    "        \"\"\"\n",
    "        Used to generate a batch with images when training/testing/validating our Keras model.\n",
    "        \"\"\"\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        while True:\n",
    "            batch_x = []\n",
    "            batch_y = []\n",
    "            \n",
    "            for idx in image_idx:\n",
    "                img_path = self.df.iloc[idx]['file'] + '.jpeg'\n",
    "                img_path = os.path.join(dataset_folder_name, img_path)\n",
    "                img = self.preprocess_image(img_path)\n",
    "                x = [self.df.iloc[idx][col]/max_x if col in ['x', 'y'] else self.df.iloc[idx][col] \n",
    "                    for col in ['x', 'y', 'left_click', 'right_click', 'w', 's', 'a', 'd', 'shift', 'e', 'q', '1', '2', 'r']]\n",
    "                \n",
    "                batch_x.append(img)\n",
    "                batch_y.append(x)\n",
    "                \n",
    "                if len(batch_x) == batch_size:\n",
    "                    yield np.array(batch_x), np.array(batch_y)\n",
    "                    batch_x = []\n",
    "                    batch_y = []\n",
    "                    \n",
    "            if not is_training:\n",
    "                break\n",
    "\n",
    "data_generator = DataGenerator(df)\n",
    "train_idx, valid_idx, test_idx = data_generator.generate_split_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class DataGenerator():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def generate_split_indexes(self):\n",
    "        p = np.random.permutation(len(df))\n",
    "        print(p)\n",
    "        train_up_to = int(len(df) * TRAIN_TEST_SPLIT)\n",
    "        train_idx = p[:train_up_to]\n",
    "        test_idx = p[train_up_to:]\n",
    "        train_up_to = int(train_up_to * TRAIN_TEST_SPLIT)\n",
    "        train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:]\n",
    "\n",
    "\n",
    "        max_x = df['x'].max()\n",
    "        max_y = df['y'].max()\n",
    "        return train_idx, valid_idx, test_idx\n",
    "\n",
    "    def preprocess_image(self, img_path):\n",
    "        \"\"\"\n",
    "        Used to perform some minor preprocessing on the image before inputting into the network.\n",
    "        \"\"\"\n",
    "        im = Image.open(img_path).convert('RGB')\n",
    "        im = im.resize((IM_WIDTH, IM_HEIGHT))\n",
    "        im = np.array(im) / 255.0\n",
    "        \n",
    "        return im\n",
    "        \n",
    "    def generate_images(self, image_idx, is_training, batch_size=16):\n",
    "        \"\"\"\n",
    "        Used to generate a batch with images when training/testing/validating our Keras model.\n",
    "        \"\"\"\n",
    "\n",
    "        x_list = []\n",
    "        y_list = []\n",
    "        left_click_list = []\n",
    "        right_click_list = []\n",
    "        w_list = []\n",
    "        s_list = []\n",
    "        a_list = []\n",
    "        d_list = []\n",
    "        shift_list = []\n",
    "        e_list = []\n",
    "        q_list = []\n",
    "        one_list = []\n",
    "        two_list = []\n",
    "        r_list = []\n",
    "        images = []\n",
    "\n",
    "\n",
    "        while True:\n",
    "            for idx in image_idx:\n",
    "\n",
    "                img_path = self.df.iloc[idx]['file']\n",
    "                img = self.preprocess_image(img_path)\n",
    "                x = self.df.iloc[idx]['x']\n",
    "                y = self.df.iloc[idx]['y']\n",
    "                left_click = self.df.iloc[idx]['left_click']\n",
    "                right_click = self.df.iloc[idx]['right_click']\n",
    "                w = self.df.iloc[idx]['w']\n",
    "                s = self.df.iloc[idx]['s']\n",
    "                a = self.df.iloc[idx]['a']\n",
    "                d = self.df.iloc[idx]['d']\n",
    "                shift = self.df.iloc[idx]['shift']\n",
    "                e = self.df.iloc[idx]['e']\n",
    "                q = self.df.iloc[idx]['q']\n",
    "                one = self.df.iloc[idx]['1']\n",
    "                two = self.df.iloc[idx]['2']\n",
    "                r = self.df.iloc[idx]['r']\n",
    "                \n",
    "\n",
    "                x_list.append(x / max_x)\n",
    "                y_list.append(y / max_y)\n",
    "                left_click_list.append(left_click)\n",
    "                right_click_list.append(right_click)\n",
    "                w_list.append(w)\n",
    "                s_list.append(s)\n",
    "                a_list.append(a)\n",
    "                d_list.append(d)\n",
    "                shift_list.append(shift)\n",
    "                e_list.append(e)\n",
    "                q_list.append(q)\n",
    "                one_list.append(one)\n",
    "                two_list.append(two)\n",
    "                r_list.append(r)\n",
    "                images.appendd(img)\n",
    "\n",
    "                if len(images) == batch_size:\n",
    "                    yield np.array(images), [np.array(images), np.array(x_list), np.array(y_list), np.array(left_click_list), np.array(right_click_list), np.array(w_list), np.array(s_list), np.array(a_list), np.array(d_list), np.array(shift_list), np.array(e_list), np.array(q_list), np.array(one_list), np.array(two_list), np.array(r_list)]\n",
    "                    x_list = []\n",
    "                    y_list = []\n",
    "                    left_click_list = []\n",
    "                    right_click_list = []\n",
    "                    w_list = []\n",
    "                    s_list = []\n",
    "                    a_list = []\n",
    "                    d_list = []\n",
    "                    shift_list = []\n",
    "                    e_list = []\n",
    "                    q_list = []\n",
    "                    one_list = []\n",
    "                    two_list = []\n",
    "                    r_list = []\n",
    "                    images = []\n",
    "\n",
    "            if not is_training:\n",
    "                break\n",
    "\n",
    "data_generator = DataGenerator(df)\n",
    "train_idx, valid_idx, test_idx = data_generator.generate_split_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = data_generator.generate_images(train_idx, is_training=True, batch_size=16)\n",
    "train_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "import tensorflow as tf\n",
    "\n",
    "class model():\n",
    "    \"\"\"\n",
    "    Used to define the model architecture.\n",
    "    \"\"\"\n",
    "\n",
    "    def conv_block(self, inputs, filters, kernel_size, padding=\"same\"):\n",
    "        x = Conv2D(filters, kernel_size,padding=padding)(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        return x\n",
    "\n",
    "    def dense_block(self, inputs, units, activation=\"relu\"):\n",
    "        x = Dense(units)(inputs)\n",
    "        x = Activation(activation)(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        return x\n",
    "\n",
    "    def default_layers(self, inputs):\n",
    "        x = self.conv_block(inputs, 16, (3, 3))\n",
    "        x = self.conv_block(x, 32, (3, 3))\n",
    "        x = self.conv_block(x, 32, (3, 3))\n",
    "        return x\n",
    "\n",
    "    def build_x_position_branch(self, inputs, num_outputs=1):\n",
    "        x = self.default_layers(inputs)\n",
    "        x = Flatten()(x)\n",
    "        x = self.dense_block(x, 128)\n",
    "        x = Dense(num_outputs)(x)\n",
    "        x = Activation(\"linear\", name='x')(x)\n",
    "        return x\n",
    "\n",
    "    def build_y_position_branch(self, inputs, num_outputs=1):\n",
    "        x = self.default_layers(inputs)\n",
    "        x = Flatten()(x)\n",
    "        x = self.dense_block(x, 128)\n",
    "        x = Dense(num_outputs)(x)\n",
    "        x = Activation(\"linear\", name='y')(x)\n",
    "        return x\n",
    "\n",
    "    def build_action_branch(self, inputs, name, num_outputs=1):\n",
    "        x = self.default_layers(inputs)\n",
    "        x = Flatten()(x)\n",
    "        x = self.dense_block(x, 128)\n",
    "        x = Dense(num_outputs)(x)\n",
    "        x = Activation(\"sigmoid\", name=name)(x)\n",
    "        return x\n",
    "\n",
    "    def build_softmax_branch(self, inputs, name, num_outputs=2):\n",
    "        x = self.default_layers(inputs)\n",
    "        x = Flatten()(x)\n",
    "        x = self.dense_block(x, 128)\n",
    "        x = Dense(num_outputs)(x)\n",
    "        x = Activation(\"softmax\", name=name)(x)\n",
    "        return x\n",
    "\n",
    "    def build_model(self, width, height):\n",
    "        inputs = Input(shape=(height, width, 3))\n",
    "        x_position = self.build_x_position_branch(inputs)\n",
    "        y_position = self.build_y_position_branch(inputs)\n",
    "        left_click = self.build_action_branch(inputs, \"left_click\")\n",
    "        right_click = self.build_action_branch(inputs, \"right_click\")\n",
    "        w = self.build_action_branch(inputs, \"w\")\n",
    "        s = self.build_action_branch(inputs, \"s\")\n",
    "        a = self.build_action_branch(inputs, \"a\")\n",
    "        d = self.build_action_branch(inputs, \"d\")\n",
    "        shift = self.build_action_branch(inputs, \"shift\")\n",
    "        e = self.build_action_branch(inputs, \"e\")\n",
    "        q = self.build_action_branch(inputs, \"q\")\n",
    "        one = self.build_action_branch(inputs, \"one\")\n",
    "        two = self.build_action_branch(inputs, \"two\")\n",
    "        r = self.build_action_branch(inputs, \"r\")\n",
    "\n",
    "\n",
    "        model = Model(inputs=inputs, outputs=[x_position, y_position, left_click, right_click, w, s, a, d, shift, e, q, one, two, r], name='bot')\n",
    "        return model\n",
    "\n",
    "    def build_soft_model(self, width, height):\n",
    "        inputs = Input(shape=(height, width, 3))\n",
    "        x_position = self.build_x_position_branch(inputs)\n",
    "        y_position = self.build_y_position_branch(inputs)\n",
    "        click = self.build_softmax_branch(inputs, \"click\")\n",
    "        for_back_move = self.build_action_branch(inputs, \"for_back_move\")\n",
    "        left_right_move = self.build_action_branch(inputs, \"left_right_move\")\n",
    "        shift = self.build_action_branch(inputs, \"shift\")\n",
    "        e = self.build_action_branch(inputs, \"e\")\n",
    "        q = self.build_action_branch(inputs, \"q\")\n",
    "        selection = self.build_softmax_branch(inputs, \"selection\")\n",
    "        r = self.build_action_branch(inputs, \"r\")\n",
    "\n",
    "        model = Model(inputs=inputs, outputs=[x_position, y_position, click, for_back_move, left_right_move, shift, e, q, selection, r], name='bot')\n",
    "        return model\n",
    "\n",
    "model = model().build_model(IM_WIDTH, IM_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "init_lr = 1e-4\n",
    "epochs = 10\n",
    "opt = Adam(lr=init_lr, decay=init_lr / epochs)\n",
    "\n",
    "actions = ['left_click','right_click','w','s','a','d','shift','e','q','one','two','r']\n",
    "\n",
    "loss = {'x': 'mse', 'y': 'mse'}\n",
    "for index, key in enumerate(actions):\n",
    "    loss[key] = 'binary_crossentropy'\n",
    "\n",
    "loss_weights = {'x': 1.0, 'y': 1.0}\n",
    "for index, key in enumerate(actions):\n",
    "    loss_weights[key] = 1.5\n",
    "\n",
    "metrics = {'x': 'mae', 'y': 'mae'}\n",
    "for index, key in enumerate(actions):\n",
    "    metrics[key] = 'accuracy'\n",
    "\n",
    "model.compile(optimizer=opt, \n",
    "              loss=loss,\n",
    "              loss_weights=loss_weights,\n",
    "              metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "batch_size = 32\n",
    "valid_batch_size = 8\n",
    "train_gen = data_generator.generate_images(train_idx, is_training=True, batch_size=batch_size)\n",
    "valid_gen = data_generator.generate_images(valid_idx, is_training=True, batch_size=valid_batch_size)\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"./model_checkpoint\", monitor='val_loss')\n",
    "]\n",
    "history = model.fit(train_gen,\n",
    "                    steps_per_epoch=len(train_idx)//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=valid_gen,\n",
    "                    validation_steps=len(valid_idx)//valid_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = plt.cm.plasma\n",
    "for layers in model.layers:\n",
    "    if str(layers.name).find(\"lstm\") != -1:\n",
    "        weights,hidden, bias = layers.get_weights()\n",
    "        plt.matshow(weights, fignum=200, cmap=color_map)\n",
    "        plt.show()\n",
    "    if str(layers.name).find(\"dense\") != -1:\n",
    "        weights, bias = layers.get_weights()\n",
    "        plt.matshow(weights, fignum=200, cmap=color_map)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpoints = list(range(0,10))\n",
    "for category in history.history:\n",
    "    if category.find(\"val\") != -1:\n",
    "        if category.find(\"loss\") != -1:\n",
    "            if category == \"val_loss\":\n",
    "                continue\n",
    "            ypoints = history.history[category]\n",
    "            plt.plot(xpoints, ypoints, label = category)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_steps=len(valid_idx)//valid_batch_size\n",
    "test_batch_size = 16\n",
    "test_generator = data_generator.generate_images(test_idx, is_training=False, batch_size=test_batch_size)\n",
    "x_pred, y_pred, left_click_pred, right_click_pred, w_pred, s_pred, a_pred, d_pred, shift_pred, e_pred, q_pred, one_pred, two_pred, r_pred = model.predict(test_generator, steps=len(test_idx)//test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = data_generator.generate_images(test_idx, is_training=False, batch_size=test_batch_size)\n",
    "samples = 1\n",
    "images, x_true, y_true, left_click_true, right_click_true, w_true, s_true, a_true, d_true, shift_true, e_true, q_true, one_true, two_true, r_true = [], [], [], [], [], [], [], [], [], [], [], [], [], [], []\n",
    "for test_batch in test_generator:\n",
    "    image = test_batch[0]\n",
    "    labels = test_batch[1]\n",
    "    \n",
    "    images.extend(image)\n",
    "    x_true.extend(labels[0])\n",
    "    y_true.extend(labels[1])\n",
    "    left_click_true.extend(labels[2])\n",
    "    right_click_true.extend(labels[3])\n",
    "    w_true.extend(labels[4])\n",
    "    s_true.extend(labels[5])\n",
    "    a_true.extend(labels[6])\n",
    "    d_true.extend(labels[7])\n",
    "    shift_true.extend(labels[8])\n",
    "    e_true.extend(labels[9])\n",
    "    q_true.extend(labels[10])\n",
    "    one_true.extend(labels[11])\n",
    "    two_true.extend(labels[12])\n",
    "    r_true.extend(labels[13])\n",
    "\n",
    "    \n",
    "x_true = np.array(x_true)\n",
    "y_true = np.array(y_true)\n",
    "left_click_true = np.array(left_click_true)\n",
    "right_click_true = np.array(right_click_true)\n",
    "w_true = np.array(w_true)\n",
    "s_true = np.array(s_true)\n",
    "a_true = np.array(a_true)\n",
    "d_true = np.array(d_true)\n",
    "shift_true = np.array(shift_true)\n",
    "e_true = np.array(e_true)\n",
    "q_true = np.array(q_true)\n",
    "one_true = np.array(one_true)\n",
    "two_true = np.array(two_true)\n",
    "r_true = np.array(r_true)\n",
    "\n",
    "x_true, y_true = x_true * data_generator.max_x, y_true * data_generator.max_y\n",
    "x_pred, y_pred = x_pred * data_generator.max_x, y_pred * data_generator.max_y\n",
    "\n",
    "left_click_true, right_click_true, w_true, s_true, a_true, d_true, shift_true, e_true, q_true, one_true, two_true, r_true = left_click_true.argmax(axis=-1), right_click_true.argmax(axis=-1), w_true.argmax(axis=-1), s_true.argmax(axis=-1), a_true.argmax(axis=-1), d_true.argmax(axis=-1), shift_true.argmax(axis=-1), e_true.argmax(axis=-1), q_true.argmax(axis=-1), one_true.argmax(axis=-1), two_true.argmax(axis=-1), r_true.argmax(axis=-1)\n",
    "left_click_pred, right_click_pred, w_pred, s_pred, a_pred, d_pred, shift_pred, e_pred, q_pred, one_pred, two_pred, r_pred = left_click_pred.argmax(axis=-1), right_click_pred.argmax(axis=-1), w_pred.argmax(axis=-1), s_pred.argmax(axis=-1), a_pred.argmax(axis=-1), d_pred.argmax(axis=-1), shift_pred.argmax(axis=-1), e_pred.argmax(axis=-1), q_pred.argmax(axis=-1), one_pred.argmax(axis=-1), two_pred.argmax(axis=-1), r_pred.argmax(axis=-1)\n",
    "\"\"\"\n",
    "race_true, gender_true = race_true.argmax(axis=-1), gender_true.argmax(axis=-1)\n",
    "race_pred, gender_pred = race_pred.argmax(axis=-1), gender_pred.argmax(axis=-1)\n",
    "age_true = age_true * data_generator.max_age\n",
    "age_pred = age_pred * data_generator.max_age\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_true, y_true = x_true.astype(int), y_true.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_true = x_true.reshape((len(x_true), 1))\n",
    "\n",
    "x_pred = x_pred.reshape((len(x_true), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print('R2 score for age: ', r2_score(x_true, x_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample()['file'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.sample()\n",
    "file = sample['file'].values[0] + '.jpeg'\n",
    "im = Image.open(os.path.join(\"Screen_Capturing/Data/\",file)).convert('RGB')\n",
    "im = im.resize((IM_WIDTH, IM_HEIGHT))\n",
    "im = np.array(im) / 255.0\n",
    "images = []\n",
    "images.append(im)\n",
    "\n",
    "images = np.array(images)\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred, y_pred, left_click_pred, right_click_pred, w_pred, s_pred, a_pred, d_pred, shift_pred, e_pred, q_pred, one_pred, two_pred, r_pred = model.predict(images)\n",
    "\n",
    "left_click_pred, right_click_pred, w_pred, s_pred, a_pred, d_pred, shift_pred, e_pred, q_pred, one_pred, two_pred, r_pred = left_click_pred.argmax(axis=-1), right_click_pred.argmax(axis=-1), w_pred.argmax(axis=-1), s_pred.argmax(axis=-1), a_pred.argmax(axis=-1), d_pred.argmax(axis=-1), shift_pred.argmax(axis=-1), e_pred.argmax(axis=-1), q_pred.argmax(axis=-1), one_pred.argmax(axis=-1), two_pred.argmax(axis=-1), r_pred.argmax(axis=-1)\n",
    "x_pred, y_pred = x_pred * max_x, y_pred * max_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred, y_pred, left_click_pred, right_click_pred, w_pred, s_pred, a_pred, d_pred, shift_pred, e_pred, q_pred, one_pred, two_pred, r_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_frame(img):\n",
    "    img = img.resize((IM_WIDTH, IM_HEIGHT))\n",
    "    img = np.array(img) / 255.0\n",
    "    images = []\n",
    "    images.append(img)\n",
    "\n",
    "    images = np.array(images)\n",
    "\n",
    "    x_pred, y_pred, left_click_pred, right_click_pred, w_pred, s_pred, a_pred, d_pred, shift_pred, e_pred, q_pred, one_pred, two_pred, r_pred = model.predict(images)\n",
    "\n",
    "    left_click_pred, right_click_pred, w_pred, s_pred, a_pred, d_pred, shift_pred, e_pred, q_pred, one_pred, two_pred, r_pred = left_click_pred.argmax(axis=-1), right_click_pred.argmax(axis=-1), w_pred.argmax(axis=-1), s_pred.argmax(axis=-1), a_pred.argmax(axis=-1), d_pred.argmax(axis=-1), shift_pred.argmax(axis=-1), e_pred.argmax(axis=-1), q_pred.argmax(axis=-1), one_pred.argmax(axis=-1), two_pred.argmax(axis=-1), r_pred.argmax(axis=-1)\n",
    "    x_pred, y_pred = x_pred * max_x, y_pred * max_y\n",
    "\n",
    "    return x_pred, y_pred, left_click_pred, right_click_pred, w_pred, s_pred, a_pred, d_pred, shift_pred, e_pred, q_pred, one_pred, two_pred, r_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import win32gui\n",
    "from PIL import ImageGrab\n",
    "from time import time\n",
    "import cv2 as cv\n",
    "\n",
    "loop_time = time()\n",
    "while(True):\n",
    "    hwnd = win32gui.FindWindow(None, 'ARMOURY CRATE')\n",
    "    rect = win32gui.GetWindowRect(hwnd)\n",
    "    screenshot = ImageGrab.grab(bbox=(rect[0], rect[1], rect[2], rect[3]))\n",
    "\n",
    "    \"\"\"screenshot = np.array(screenshot)\n",
    "    screenshot = cv.cvtColor(screenshot, cv.COLOR_RGB2BGR)\"\"\"\n",
    "\n",
    "    print(pred_frame(screenshot))\n",
    "\n",
    "    screenshot = np.array(screenshot)\n",
    "    screenshot = cv.cvtColor(screenshot, cv.COLOR_RGB2BGR)\n",
    "\n",
    "    cv.imshow('Computer Vision', screenshot)\n",
    "\n",
    "    print('FPS {}'.format(1 / (time() - loop_time)))\n",
    "    loop_time = time()\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d08972ed514e224d1c8b56251ea08bdda2834a6f4aa521d36903282eac70a81e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
